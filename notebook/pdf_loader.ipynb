{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d135e55b",
   "metadata": {},
   "source": [
    "### RAG Pipelines Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8952b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sha/Developer/RAG langchain/RAG_VENV/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23210ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 129 documents from ../data\n"
     ]
    }
   ],
   "source": [
    "def process_all_pdfs(pdf_directory : str):\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        pdf_directory,\n",
    "        glob = \"**/*.pdf\",\n",
    "        loader_cls = PyMuPDFLoader,\n",
    "        show_progress = False\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    for doc in documents:\n",
    "        doc.metadata['source_file'] = Path(doc.metadata['source']).name\n",
    "        doc.metadata['file_type'] = 'pdf'\n",
    "    print(f\"\\n✅ Loaded {len(documents)} documents from {pdf_directory}\")\n",
    "    return documents\n",
    "\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c9e4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 5, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}, page_content='6 \\n \\n \\ncomputer for processing, which increases the response time. \\n➢ Lower Communication Cost  \\n• In distributed database systems, if data is located locally where it is mostly used, then \\nthe communication costs for data manipulation can be minimized.  \\n• This is not feasible in centralized systems. \\n \\nWhy Distributed Databases \\n➢ Organizational and economic reasons \\n➢ Interconnection of existing databases \\n➢ Incremental growth \\n➢ Reduced communication overhead \\n➢ Performance considerations \\n➢ Reliability and availability \\n \\nDifficult of Distributed Databases \\n➢ Need for complex and expensive software  \\nDDBMS demands complex and often expensive software to provide data transparency and co-\\nordination across the several sites. \\n \\n➢ Processing overhead \\nEven simple operations may require a large number of communications and additional \\ncalculations to provide uniformity in data across the sites. \\n \\n➢ Data integrity  \\nThe need for updating data in multiple sites pose problems of data integrity. \\n \\n➢ Overheads for improper data distribution \\nResponsiveness of queries is largely dependent upon proper data distribution. Improper data \\ndistribution often leads to very slow response to user requests. \\n \\nData Allocation \\nData Allocation is an intelligent distribution of your data pieces, (called data fragments) to \\nimprove database performance and Data Availability for end-users. It aims to reduce overall \\ncosts of transaction processing while also providing accurate data rapidly in your DDBMS \\nsystems. Data Allocation is one of the key steps in building your Distributed Database Systems. \\nThere are two common strategies used in optimal Data Allocation: Data Fragmentation and \\nData Replication. \\n \\nFragmentation and Replication In Distributed Database \\n \\nData Fragmentation \\n➢ Fragmentation is a process of disintegrating relations or tables into several partitions in \\nmultiple sites.  \\n➢ It divides a database into various subtables and sub relations so that data can be \\ndistributed and stored efficiently.  \\n➢ Database Fragmentation can be of two types: horizontal or vertical.  \\n➢ In a horizontal fragmentation, each tuple of a relation r is assigned to one or more \\nfragments.  \\n➢ In vertical fragmentation, the schema for a relation r is split into numerous smaller')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31918a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### process all pdfs inside directory \n",
    "\n",
    "# def process_all_pdfs(pdf_directory):\n",
    "#     ## process all pdf in the directory \n",
    "#     all_documents = []\n",
    "#     pdf_dir = Path(pdf_directory)\n",
    "\n",
    "#     ##find all pdf files recursively\n",
    "#     pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "#     print(f\"found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "#     for pdf_file in pdf_files:\n",
    "#         print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "#         try:\n",
    "#             loader = PyPDFLoader(str(pdf_file))\n",
    "#             documents = loader.load()\n",
    "\n",
    "#             ## add source info to metadata\n",
    "#             for doc in documents:\n",
    "#                 doc.metadata['source_file'] = pdf_file.name\n",
    "#                 doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "#             all_documents.extend(documents)\n",
    "#             print(f\" Loaded {len(documents)} pages\")\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(f\" Error: {e}\")\n",
    "            \n",
    "#     print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "#     return all_documents\n",
    "\n",
    "# # process all documents in data directory\n",
    "# all_pdf_documents = process_all_pdfs(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ea8d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 0, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}\n",
      "{'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 1, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}\n",
      "{'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 2, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}\n",
      "{'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 3, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}\n",
      "{'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 4, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in all_pdf_documents[:5]:  # first 5 docs\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d9365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### text splitting into chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    #splitting documents into smaller chunks for better RAG performance\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap,\n",
    "        length_function = len,\n",
    "        separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    #show example of chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649fd977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 129 documents into 319 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: 1 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "SCHOOL OF COMPUTING \n",
      " \n",
      "DEPARTMENT OF COMPUTER SCIENCE AND \n",
      "ENGINEERING \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     \n",
      " \n",
      "    UNIT – I  - DISTRIBUTED DATABASE AND INFORMATION SY...\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 0, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb67c04",
   "metadata": {},
   "source": [
    "### Embedding and VectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22072edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06cfa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedded model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimensions: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x11d68dbe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    # handles document embedding generation using SentenceTransformer\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        # initialise embedding manager\n",
    "        #args: model_name = HuggingFace model for sentence embedding\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        # load SentenceTransformer model\n",
    "        try:\n",
    "            print(f\"Loading embedded model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimensions: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading the model {self.model_name} : {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts : List[str]) -> np.ndarray:\n",
    "        # generate embedding for list of texts\n",
    "\n",
    "        #args:\n",
    "            # texts: list of text strings to embeddings\n",
    "\n",
    "        # returns:\n",
    "            # numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not Loaded\")\n",
    "\n",
    "        print(f\"generate embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"generated embeddings with shape: {embeddings.shape}\")\n",
    "\n",
    "        return embeddings\n",
    "    \n",
    "## initialise the embeddding manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034f435",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b295f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection : pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x11d68d940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    # manage document embeddings in chromaDB vector store\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        # initialize the vector store\n",
    "\n",
    "        # Args:\n",
    "            # collection_name : name of chromaDB collection\n",
    "            # persist_directory : directory to persist the vector store\n",
    "        \n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "    \n",
    "    def _initialize_store(self):\n",
    "        # initialize chromaDB client and collection\n",
    "        try:\n",
    "            #create persistent chromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "\n",
    "            #get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata={\"description\" : \"PDF documents for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection : {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents : List[Any], embeddings: np.ndarray):\n",
    "        # add documents and their embeddings to the vector store\n",
    "\n",
    "        # Args:\n",
    "            #documents: list of LangChain documents\n",
    "            #embeddings: corresponding embeddings for the documents\n",
    "\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # prepare data for chromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # generate unique id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # ids = []\n",
    "        # metadatas = []\n",
    "        # documents_text = []\n",
    "        # embeddings_list = []\n",
    "\n",
    "        # for i in range(len(documents)):\n",
    "        #     doc = documents[i]\n",
    "        #     embedding = embeddings[i]\n",
    "\n",
    "        #     # Generate a unique document ID\n",
    "        #     doc_id = \"doc_\" + uuid.uuid4().hex[:8] + \"_\" + str(i)\n",
    "        #     ids.append(doc_id)\n",
    "\n",
    "        #     # Prepare metadata dictionary\n",
    "        #     metadata = dict(doc.metadata)\n",
    "        #     metadata[\"doc_index\"] = i\n",
    "        #     metadata[\"content_length\"] = len(doc.page_content)\n",
    "        #     metadatas.append(metadata)\n",
    "\n",
    "        #     # Store document content\n",
    "        #     documents_text.append(doc.page_content)\n",
    "\n",
    "        #     # Store embedding as list\n",
    "        #     embeddings_list.append(embedding.tolist())\n",
    "\n",
    "\n",
    "        # add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids,\n",
    "                embeddings = embeddings_list,\n",
    "                metadatas = metadatas,\n",
    "                documents = documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to Vector Store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding  documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore = VectorStore()\n",
    "vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6d0095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 0, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}, page_content='1 \\n \\n \\n \\n \\n \\n \\nSCHOOL OF COMPUTING \\n \\nDEPARTMENT OF COMPUTER SCIENCE AND \\nENGINEERING \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n     \\n \\n    UNIT – I  - DISTRIBUTED DATABASE AND INFORMATION SYSTEMS- SCSA3008'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 1, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}, page_content='2 \\n \\n \\nSCSA3008_DISTRIBUTED DATABASE AND INFORMATION \\nSYSTEMS \\nCOURSE OBJECTIVES  \\n \\n➢ To understand the role of databases and database management systems in \\nmanaging organizational data and information. \\n➢ To understand the techniques used for data fragmentation, replication and \\nallocation during the distributed database design process. \\n➢ To discuss the issues involved in resource management and process. \\n➢ To Perceive the building blocks and design of information systems. \\n➢ To acquire knowledge of information systems on Business operations. \\n \\nCOURSE OUTCOMES  \\nOn completion of the course, student will be able to \\nCO1 - Identify the introductory distributed database concepts and its structures. \\nCO2 - Produce the transaction management and query processing techniques in  \\n           DDBMS. \\nCO3 - Develop in-depth understanding of relational databases and skills to optimize  \\n          database performance in practice. \\nCO4 - Critiques on each type of databases.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 1, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}, page_content='DDBMS. \\nCO3 - Develop in-depth understanding of relational databases and skills to optimize  \\n          database performance in practice. \\nCO4 - Critiques on each type of databases. \\nCO5 - Analyse, Design and present the information systems. \\nC06 - Designing of decision support system and tools for Business operations. \\n \\nUNIT 1      9 Hrs. \\nINTRODUCTORY CONCEPTS AND DESIGN OF (DDBMS) \\nData Fragmentation - Replication and allocation techniques for DDBMS - Methods \\nfor designing and implementing DDBMS - designing a distributed relational \\ndatabase - Architectures for DDBMS - Cluster federated - parallel databases and \\nclient server architecture - Overview of query processing. \\nUNIT 2    9 Hrs. \\nDISTRIBUTED \\nSECURITY \\nAND \\nDISTRIBUTED \\nDATABASE \\nAPPLICATION TECHNOLOGIES \\nOverview of security techniques - Cryptographic algorithms - Digital signatures - \\nDistributed Concurrency Control - Serializability theory - Taxonomy of concurrency'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 1, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}, page_content='APPLICATION TECHNOLOGIES \\nOverview of security techniques - Cryptographic algorithms - Digital signatures - \\nDistributed Concurrency Control - Serializability theory - Taxonomy of concurrency \\ncontrol mechanisms - Distributed deadlocks – Distributed Database Recovery - \\nDistributed Data Security - Web data management - Database Interoperability. \\nUNIT 3      9 Hrs \\nADVANCED IN DISTRIBUTED SYSTEMS \\nAuthentication in distributed systems - Protocols based on symmetric cryptosystems \\n- Protocols based on asymmetric cryptosystems - Password-based authentication - \\nUnstructured overlays - Chord distributed hash table – Content addressable'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2022-12-17T08:32:38+00:00', 'source': '../data/pdf_files/unit2.pdf', 'file_path': '../data/pdf_files/unit2.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2022-12-17T08:32:38+00:00', 'trapped': '', 'modDate': \"D:20221217083238+00'00'\", 'creationDate': \"D:20221217083238+00'00'\", 'page': 2, 'source_file': 'unit2.pdf', 'file_type': 'pdf'}, page_content='3 \\n \\n \\nnetworks (CAN) - Tapestry - Some other challenges in P2P system design - \\nTradeoffs between table storage and route lengths - Graph structures of complex \\nnetworks - Internet graphs - Generalized random graph networks. \\nUNIT 4       9 Hrs. \\nFUNDAMENTALAS OF INFORMATION SYSTEMS \\nDefining information – Classification of information – Presentation of information \\nsystems – Basics of Information systems –  Functions of information systems – \\nComponents of Information systems- Limitations of Information systems – \\nInformation System Design. \\nUNIT 5       9 Hrs. \\n ENTERPRISE COLLOBRATION SYSTEMS \\nGroupware – Types of groupware – Enterprise Communication tools – Enterprise \\nConferencing tools – Collaborative work management tools – Information System \\nfor Business operations – transaction processing systems – functional Information \\nSystems – Decision Support systems – Executive Information systems – Online \\nAnalytical processing.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae21c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate embeddings for 319 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 10/10 [00:02<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (319, 384)\n",
      "Adding 319 documents to vector store...\n",
      "Successfully added 319 documents to Vector Store\n",
      "Total documents in collection: 319\n"
     ]
    }
   ],
   "source": [
    "# convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "# generate the embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "# store it in the vector database\n",
    "vectorstore.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69194fe9",
   "metadata": {},
   "source": [
    "### Retriever Pipeline query retriever for Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b258815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    # handles query based retriver for rag.\n",
    "\n",
    "    def __init__(self, vector_store : VectorStore, embedding_manager: EmbeddingManager):\n",
    "        # initialize retriever\n",
    "        #args:\n",
    "            # vector_store: vector store containing document embeddings.\n",
    "            # embedding_manager : manager for generating query embeddings.\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query : str, top_k : int = 5, score_threshold : float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query : '{query}'\")\n",
    "        print(f\"Top K : {top_k}, score threshold: {score_threshold}\")\n",
    "\n",
    "        # generate query embedding\n",
    "        query_embedding  = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # search in vector database\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings = [query_embedding.tolist()],\n",
    "                n_results = top_k\n",
    "            )\n",
    "            # process results\n",
    "            retrieved_docs = []\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                # for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                # # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                # similarity_score = 1 - distance\n",
    "                \n",
    "                # if similarity_score >= score_threshold:\n",
    "                #     retrieved_docs.append({\n",
    "                #         'id': doc_id,\n",
    "                #         'content': document,\n",
    "                #         'metadata': metadata,\n",
    "                #         'similarity_score': similarity_score,\n",
    "                #         'distance': distance,\n",
    "                #         'rank': i + 1\n",
    "                #     })\n",
    "                index = 0\n",
    "                for doc_id in ids:\n",
    "                    document = documents[index]\n",
    "                    metadata = metadatas[index]\n",
    "                    distance = distances[index]\n",
    "\n",
    "                    similarity_score = 1 - distance\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id' : doc_id,\n",
    "                            'content' : document,\n",
    "                            'metadata' : metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': index + 1\n",
    "                        })\n",
    "                    index += 1\n",
    "\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            return retrieved_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "                \n",
    "rag_retriever = RAGRetriever(vectorstore, embedding_manager)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fb90837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query : 'what is digital signature'\n",
      "Top K : 5, score threshold: 0.0\n",
      "generate embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_2874f6fc_65',\n",
       "  'content': 'Digital Signatures \\nA digital signature is a mathematical scheme for verifying the authenticity of digital \\nmessages or documents. A valid digital signature, where the prerequisites are satisfied, \\ngives a recipient very high confidence that the message was created by a known sender, \\nand that the message was not altered in transit.  \\nDigital signatures are a standard element of most cryptographic protocol suites, and are \\ncommonly used for software distribution, financial transactions, contract management \\nsoftware, and in other cases where it is important to detect forgery or tampering. \\nDigital signatures are often used to implement electronic signatures, which includes any \\nelectronic data that carries the intent of a signature, but not all electronic signatures use \\ndigital signatures.   \\nDigital signatures employ asymmetric cryptography. In many instances, they provide a \\nlayer of validation and security to messages sent through a non-secure channel: Properly',\n",
       "  'metadata': {'creationdate': '2023-01-17T09:24:21+00:00',\n",
       "   'creationDate': \"D:20230117092421+00'00'\",\n",
       "   'moddate': '2023-01-17T09:24:21+00:00',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'file_type': 'pdf',\n",
       "   'format': 'PDF 1.7',\n",
       "   'source_file': 'unit3.pdf',\n",
       "   'content_length': 979,\n",
       "   'file_path': '../data/pdf_files/unit3.pdf',\n",
       "   'trapped': '',\n",
       "   'keywords': '',\n",
       "   'total_pages': 38,\n",
       "   'source': '../data/pdf_files/unit3.pdf',\n",
       "   'producer': 'Microsoft® Word for Microsoft 365',\n",
       "   'creator': 'Microsoft® Word for Microsoft 365',\n",
       "   'modDate': \"D:20230117092421+00'00'\",\n",
       "   'title': '',\n",
       "   'page': 5,\n",
       "   'doc_index': 65},\n",
       "  'similarity_score': 0.6377941370010376,\n",
       "  'distance': 0.3622058629989624,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_3270805d_127',\n",
       "  'content': 'A Digital Signature (DS) is an authentication technique based on public key cryptography used \\nin e-commerce applications. It associates a unique mark to an individual within the body of his \\nmessage. This helps others to authenticate valid senders of messages. \\nTypically, a user’s digital signature varies from message to message in order to provide security \\nagainst counterfeiting. The method is as follows − \\n• \\nThe sender takes a message, calculates the message digest of the message and \\nsigns it digest with a private key. \\n• \\nThe sender then appends the signed digest along with the plaintext message. \\n• \\nThe message is sent over communication channel. \\n• \\nThe receiver removes the appended signed digest and verifies the digest using the \\ncorresponding public key. \\n• \\nThe receiver then takes the plaintext message and runs it through the same \\nmessage digest algorithm. \\n• \\nIf the results of step 4 and step 5 match, then the receiver knows that the message',\n",
       "  'metadata': {'format': 'PDF 1.7',\n",
       "   'trapped': '',\n",
       "   'keywords': '',\n",
       "   'title': '',\n",
       "   'file_type': 'pdf',\n",
       "   'moddate': '2023-01-17T09:24:21+00:00',\n",
       "   'modDate': \"D:20230117092421+00'00'\",\n",
       "   'content_length': 969,\n",
       "   'doc_index': 127,\n",
       "   'subject': '',\n",
       "   'source': '../data/pdf_files/unit3.pdf',\n",
       "   'producer': 'Microsoft® Word for Microsoft 365',\n",
       "   'total_pages': 38,\n",
       "   'creationdate': '2023-01-17T09:24:21+00:00',\n",
       "   'creator': 'Microsoft® Word for Microsoft 365',\n",
       "   'file_path': '../data/pdf_files/unit3.pdf',\n",
       "   'source_file': 'unit3.pdf',\n",
       "   'author': '',\n",
       "   'page': 31,\n",
       "   'creationDate': \"D:20230117092421+00'00'\"},\n",
       "  'similarity_score': 0.5651180744171143,\n",
       "  'distance': 0.43488192558288574,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_580a580e_66',\n",
       "  'content': 'digital signatures.   \\nDigital signatures employ asymmetric cryptography. In many instances, they provide a \\nlayer of validation and security to messages sent through a non-secure channel: Properly \\nimplemented, a digital signature gives the receiver reason to believe the message was sent \\nby the claimed sender. Digital signatures are equivalent to traditional handwritten \\nsignatures in many respects, but properly implemented digital signatures are more \\ndifficult to forge than the handwritten type. Digital signature schemes, in the sense used \\nhere, are cryptographically based, and must be implemented properly to be effective. \\nThey can also provide non-repudiation, meaning that the signer cannot successfully claim \\nthey did not sign a message, while also claiming their private key remains secret. Further, \\nsome non-repudiation schemes offer a timestamp for the digital signature, so that even if \\nthe private key is exposed, the signature is valid. Digitally signed messages may be',\n",
       "  'metadata': {'trapped': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft® Word for Microsoft 365',\n",
       "   'source_file': 'unit3.pdf',\n",
       "   'total_pages': 38,\n",
       "   'creationdate': '2023-01-17T09:24:21+00:00',\n",
       "   'page': 5,\n",
       "   'moddate': '2023-01-17T09:24:21+00:00',\n",
       "   'format': 'PDF 1.7',\n",
       "   'creationDate': \"D:20230117092421+00'00'\",\n",
       "   'doc_index': 66,\n",
       "   'source': '../data/pdf_files/unit3.pdf',\n",
       "   'producer': 'Microsoft® Word for Microsoft 365',\n",
       "   'modDate': \"D:20230117092421+00'00'\",\n",
       "   'file_path': '../data/pdf_files/unit3.pdf',\n",
       "   'content_length': 995,\n",
       "   'title': '',\n",
       "   'file_type': 'pdf',\n",
       "   'author': ''},\n",
       "  'similarity_score': 0.4338730573654175,\n",
       "  'distance': 0.5661269426345825,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_fb991238_67',\n",
       "  'content': 'some non-repudiation schemes offer a timestamp for the digital signature, so that even if \\nthe private key is exposed, the signature is valid. Digitally signed messages may be \\nanything representable as a bitstring: examples include electronic mail, contracts, or a \\nmessage sent via some other cryptographic protocol. \\n \\nFig 2.1 Digital Signature \\nAlice signs a message—\"Hello Bob!\"—by appending a signature computed from the \\nmessage and her private key. Bob receives both the message and signature. He uses \\nAlice\\'s public key to verify the authenticity of the signed message shown in Fig 2.1.',\n",
       "  'metadata': {'file_path': '../data/pdf_files/unit3.pdf',\n",
       "   'creator': 'Microsoft® Word for Microsoft 365',\n",
       "   'modDate': \"D:20230117092421+00'00'\",\n",
       "   'trapped': '',\n",
       "   'format': 'PDF 1.7',\n",
       "   'doc_index': 67,\n",
       "   'subject': '',\n",
       "   'creationDate': \"D:20230117092421+00'00'\",\n",
       "   'file_type': 'pdf',\n",
       "   'page': 5,\n",
       "   'creationdate': '2023-01-17T09:24:21+00:00',\n",
       "   'content_length': 596,\n",
       "   'source_file': 'unit3.pdf',\n",
       "   'keywords': '',\n",
       "   'author': '',\n",
       "   'moddate': '2023-01-17T09:24:21+00:00',\n",
       "   'title': '',\n",
       "   'total_pages': 38,\n",
       "   'producer': 'Microsoft® Word for Microsoft 365',\n",
       "   'source': '../data/pdf_files/unit3.pdf'},\n",
       "  'similarity_score': 0.3927578330039978,\n",
       "  'distance': 0.6072421669960022,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_8a246d6f_126',\n",
       "  'content': 'message, the receiver decrypts it using his private key. Since the private key is not known to \\nanyone but the receiver, no other person who receives the message can decrypt it. \\nThe most popular public key cryptography algorithms are RSA algorithm and Diffie– \\nHellman algorithm. This method is very secure to send private messages. However, the problem \\nis, it involves a lot of computations and so proves to be inefficient for long messages. \\nThe solution is to use a combination of conventional and public key cryptography. The secret \\nkey is encrypted using public key cryptography before sharing between the communicating \\nparties. Then, the message is send using conventional cryptography with the aid of the shared \\nsecret key. \\nDigital Signatures \\nA Digital Signature (DS) is an authentication technique based on public key cryptography used \\nin e-commerce applications. It associates a unique mark to an individual within the body of his',\n",
       "  'metadata': {'page': 31,\n",
       "   'keywords': '',\n",
       "   'file_path': '../data/pdf_files/unit3.pdf',\n",
       "   'moddate': '2023-01-17T09:24:21+00:00',\n",
       "   'author': '',\n",
       "   'modDate': \"D:20230117092421+00'00'\",\n",
       "   'title': '',\n",
       "   'format': 'PDF 1.7',\n",
       "   'creator': 'Microsoft® Word for Microsoft 365',\n",
       "   'source': '../data/pdf_files/unit3.pdf',\n",
       "   'trapped': '',\n",
       "   'creationDate': \"D:20230117092421+00'00'\",\n",
       "   'total_pages': 38,\n",
       "   'doc_index': 126,\n",
       "   'creationdate': '2023-01-17T09:24:21+00:00',\n",
       "   'subject': '',\n",
       "   'content_length': 947,\n",
       "   'producer': 'Microsoft® Word for Microsoft 365',\n",
       "   'source_file': 'unit3.pdf',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.3577728867530823,\n",
       "  'distance': 0.6422271132469177,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"what is digital signature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95850798",
   "metadata": {},
   "source": [
    "### Integration vectorDB context pipeline with LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae085df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple RAG pipeline with groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "\n",
    "## initialize groq LLM with groq API key\n",
    "groq_api_key = \"\"\n",
    "\n",
    "llm = ChatGroq(groq_api_key = groq_api_key, model = \"llama-3.3-70b-versatile\", temperature = 0.1, max_tokens = 1024)\n",
    "\n",
    "# simple RAG function : retrieve context + generate response\n",
    "def rag_simple(query, retriever, llm, top_k = 3):\n",
    "    #retriever the context\n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevent context found to answer the question.\"\n",
    "    \n",
    "    # generate answer using groq llm\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccfb7b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query : 'what are the 5 classification of information system'\n",
      "Top K : 3, score threshold: 0.0\n",
      "generate embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the classification of information systems is not explicitly listed as 5. However, it mentions two main classifications: \n",
      "\n",
      "1. Operations support system\n",
      "2. Management support system\n",
      "\n",
      "Additionally, under the \"PRESENTATION OF INFORMATION SYSTEMS\" section, it mentions four main types of information systems:\n",
      "\n",
      "1. Operations support systems\n",
      "2. Management information systems\n",
      "3. (The context does not explicitly mention the other two types, but it does mention Decision Support System in a different section)\n",
      "\n",
      "Note that the context does not provide a clear list of 5 classifications of information systems.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"what are the 5 classification of information system\", rag_retriever, llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca4810",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1759dd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query : 'what are the 5 classification of information system'\n",
      "Top K : 3, score threshold: 0.1\n",
      "generate embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided context, the classification of information systems is not explicitly listed as 5. However, it mentions two main classifications: \n",
      "\n",
      "1. Operations support system\n",
      "2. Management support system\n",
      "\n",
      "And later, it mentions four main types of information systems:\n",
      "\n",
      "1. Operations support systems\n",
      "2. Management information systems\n",
      "3. (The other two types are not explicitly mentioned in the provided context, but they are often referred to as)\n",
      "4. Decision support systems\n",
      "5. Executive support systems (not mentioned in the context, but a common classification)\n",
      "\n",
      "Note: The context does not provide a clear list of 5 classifications, but based on general knowledge, the above list can be considered.\n",
      "Sources: [{'source': 'unit4.pdf', 'page': 4, 'score': 0.3658398389816284, 'preview': 'Information is data that has been processed into a form that is meaningful to the user. \\nAn information system (IS) is an organized combination of people, hardware, software, \\ncommunications network, and data resources that collects, transforms and disseminates \\ninformation in an organization. Infor...'}, {'source': 'unit4.pdf', 'page': 2, 'score': 0.3065508008003235, 'preview': 'Information technology has helped drive efficiency across organization with improved \\nproductivity and precision manufacturing. \\n \\nFuture of Information System and Information Technology \\n \\nInformation technology has shown exponential growth in the last decade, leading to \\nmore sophisticated informa...'}, {'source': 'unit4.pdf', 'page': 3, 'score': 0.2941209077835083, 'preview': 'routine decision-making process. Decision support system provides information to \\nmanager facilitating specific issue related solution. \\n \\nPRESENTATION OF INFORMATION SYSTEMS \\n \\nThere are various information systems, and the type of information system a business \\nuses depends on its goal and objecti...'}]\n",
      "Confidence: 0.3658398389816284\n",
      "Context Preview: Information is data that has been processed into a form that is meaningful to the user. \n",
      "An information system (IS) is an organized combination of people, hardware, software, \n",
      "communications network, and data resources that collects, transforms and disseminates \n",
      "information in an organization. Infor\n"
     ]
    }
   ],
   "source": [
    "def rag_advanced(query, retriever, llm, top_k = 3, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "        rag pipeline with extra features\n",
    "        return answer, sources , confidence score, and optionally full context\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'source':[], 'confidence':0.0, 'context':0}\n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"what are the 5 classification of information system\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "714043a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query : 'what is information system'\n",
      "Top K : 3, score threshold: 0.1\n",
      "generate embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Streaming answer:\n",
      "Use the following context to answer the question concisely.\n",
      "Context:\n",
      "and introduction of computers. \n",
      " \n",
      "Information System \n",
      " \n",
      "An information system can be defined as set of coordinated network of components, \n",
      "which act together towards producing, distributing and or processing information. An \n",
      "important characteristic o"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f computer-based information systems information is \n",
      "precision, which may not apply to other types. \n",
      "In any given organization information system can be classified based on the usage of the \n",
      "information. Therefore, information systems in business can be divided into operations \n",
      "support system and management support system. \n",
      " \n",
      "Information Technology \n",
      " \n",
      "Everyday knowingly or unknowingly, everyone is utilizing information technology. It \n",
      "has grown rapidly and covers many areas of our day to day life like movies, mobile \n",
      "phones, the internet, etc. \n",
      "Information technology can be broadly defined as integration of computer with \n",
      "telecommunication equipment for storing, retrieving, manipulating and storage of data.\n",
      "\n",
      "Information is data that has been processed into a form that is meaningful to the user. \n",
      "An information system (IS) is an organized combination of people, hardware, software, \n",
      "communications network, and data resources that collects, transforms and disseminates \n",
      "information in an organization. Information systems and technologies have become a \n",
      "vital component of businesses and organizations. People rely on information systems to \n",
      "communicate with each other using a variety of physical devices (hardware), \n",
      "information processing instructions and procedures (software), communication channels \n",
      "(networks), and stored data (data resources). Information can be classified into facts, \n",
      "opinions, concepts, procedures, processes, principles, primary information, and \n",
      "secondary information. Apart from this, it can also be classified into several types based \n",
      "on its nature, usage, creation, application, structure, and form.\n",
      "\n",
      "5 \n",
      " \n",
      " \n",
      "•Better data storage and accessSuch a system is also useful for storing operational data, \n",
      "documents, communication records, and histories. As manual data may cost a lot of \n",
      "time, information systems can be very helpful in it. Information system stores data in a \n",
      "sophisticated manner, making the process of finding the data much easier. \n",
      " \n",
      "•Better decision making Information system helps a business in its decision-making \n",
      "process. With an information system, delivering all the important information is easier \n",
      "to make better decisions. In addition, an information system allows employees to \n",
      "communicate effectively. As the documents are stored in folders, it is easier to share and \n",
      "access them with the employees. \n",
      " \n",
      " \n",
      "BASICS OF INFORMATION SYSTEMS \n",
      " \n",
      "Information is data that has been processed into a form that is meaningful to the user. \n",
      "An information system (IS) is an organized combination of people, hardware, software,\n",
      "\n",
      "Question: what is information system\n",
      "\n",
      "Answer:\n",
      "\n",
      "Final Answer: An information system is a set of coordinated network of components that act together to produce, distribute, and process information. It is an organized combination of people, hardware, software, communications network, and data resources that collects, transforms, and disseminates information in an organization.\n",
      "\n",
      "Citations:\n",
      "[1] unit4.pdf (page 1)\n",
      "[2] unit4.pdf (page 4)\n",
      "[3] unit4.pdf (page 4)\n",
      "Summary: An information system is a network of components that work together to collect, process, and distribute information within an organization. It consists of a combination of people, hardware, software, communications networks, and data resources that are coordinated to transform and disseminate information effectively.\n",
      "History: {'question': 'what is information system', 'answer': 'An information system is a set of coordinated network of components that act together to produce, distribute, and process information. It is an organized combination of people, hardware, software, communications network, and data resources that collects, transforms, and disseminates information in an organization.', 'sources': [{'source': 'unit4.pdf', 'page': 1, 'score': 0.6287165880203247, 'preview': 'and introduction of computers. \\n \\nInformation System \\n \\nAn information system can be defined as set of coordinated netwo...'}, {'source': 'unit4.pdf', 'page': 4, 'score': 0.590800404548645, 'preview': 'Information is data that has been processed into a form that is meaningful to the user. \\nAn information system (IS) is a...'}, {'source': 'unit4.pdf', 'page': 4, 'score': 0.47998595237731934, 'preview': '5 \\n \\n \\n•Better data storage and accessSuch a system is also useful for storing operational data, \\ndocuments, communicati...'}], 'summary': 'An information system is a network of components that work together to collect, process, and distribute information within an organization. It consists of a combination of people, hardware, software, communications networks, and data resources that are coordinated to transform and disseminate information effectively.'}\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"what is information system\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
